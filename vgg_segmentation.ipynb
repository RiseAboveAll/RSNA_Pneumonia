{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "vgg segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiseAboveAll/RSNA_Pneumonia/blob/master/vgg_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txi08tXZYKGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2bee358c-d730-4c3a-ea7d-a0be9b7d9730"
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 98kB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlGD0kMtTAR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1b44f9f0-bbd6-4231-afc4-0a2fcca76e12"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns\n",
        "\n",
        "import pydicom\n",
        "\n",
        "import csv\n",
        "import random\n",
        "\n",
        "from glob import glob #The glob module finds all the pathnames matching a specified pattern according to the rules\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from skimage import measure\n",
        "from skimage.transform import resize\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "import math\n",
        "import cv2\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "#from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.backend import epsilon\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1-NUp5qTtTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f847f98-9578-47e1-90f7-9ef5f64ba804"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG7f89n-Zktm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Path='/content/drive/My Drive/'\n",
        "Image_Path='/content/drive/My Drive/Capstone/train_images/'\n",
        "os.chdir(Path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq9nVO3GTASC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1526af9e-5c76-4fe8-f4cc-c55585015806"
      },
      "source": [
        "pneumonia_locations = {}\n",
        "# load table\n",
        "with open('/content/drive/My Drive/Capstone/sub_data.csv', mode='r') as infile:\n",
        "\n",
        "    # open reader\n",
        "  reader = csv.reader(infile)\n",
        "    # skip header\n",
        "  next(reader, None)\n",
        "    # loop through rows\n",
        "  for rows in reader:\n",
        "    # retrieve information\n",
        "    filename = rows[0]\n",
        "    location = rows[1:5]\n",
        "    pneumonia = rows[5]\n",
        "        # if row contains pneumonia add label to dictionary\n",
        "        # which contains a list of pneumonia locations per filename\n",
        "    if pneumonia == '1':\n",
        "      # convert string to float to int\n",
        "      location = [int(float(i)) for i in location]\n",
        "      # save pneumonia location in dictionary\n",
        "      if filename in pneumonia_locations:\n",
        "        pneumonia_locations[filename].append(location)\n",
        "      else:\n",
        "        pneumonia_locations[filename] = [location]\n",
        "folder = '/content/drive/My Drive/Capstone/train_images/'\n",
        "filenames = os.listdir(folder)\n",
        "random.shuffle(filenames)\n",
        "# split into train and validation filenames\n",
        "n_valid_samples = 2560\n",
        "train_filenames = filenames[n_valid_samples:]\n",
        "valid_filenames = filenames[:n_valid_samples]\n",
        "print('n train samples', len(train_filenames))\n",
        "print('n valid samples', len(valid_filenames))\n",
        "n_train_samples = len(filenames) - n_valid_samples\n",
        "folder = '/content/drive/My Drive/Capstone/train_images'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n train samples 24126\n",
            "n valid samples 2560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czRrwzG69rCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEvqhbFdTASI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class generator(keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=32, image_size=256, shuffle=True, augment=False, predict=False):\n",
        "        self.folder = folder\n",
        "        self.filenames = filenames\n",
        "        self.pneumonia_locations = pneumonia_locations\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.predict = predict\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __load__(self, filename):\n",
        "        # load dicom file as numpy array\n",
        "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
        "        # create empty mask\n",
        "        msk = np.zeros((img.shape,3),dtype=float)\n",
        "        # get filename without extension\n",
        "        filename = filename.split('.')[0]\n",
        "        # if image contains pneumonia\n",
        "        if filename in pneumonia_locations:\n",
        "            # loop through pneumonia\n",
        "            for location in pneumonia_locations[filename]:\n",
        "                # add 1's at the location of the pneumonia\n",
        "                x, y, w, h = location\n",
        "                msk[y:y+h, x:x+w] = 1\n",
        "        # if augment then horizontal flip half the time\n",
        "        if self.augment and random.random() > 0.5:\n",
        "            img = np.fliplr(img)\n",
        "            msk = np.fliplr(msk)\n",
        "        # resize both image and mask\n",
        "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
        "        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5\n",
        "        # add trailing channel dimension\n",
        "        img = np.expand_dims(img, -1)\n",
        "        msk = np.expand_dims(msk, -1)\n",
        "        return img, msk\n",
        "    \n",
        "    def __loadpredict__(self, filename):\n",
        "        # load dicom file as numpy array\n",
        "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
        "        img=np.expand_dims()\n",
        "        # resize image\n",
        "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
        "        # add trailing channel dimension\n",
        "        img = np.expand_dims(img, -1)\n",
        "        return img\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # select batch\n",
        "        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # predict mode: return images and filenames\n",
        "        if self.predict:\n",
        "            # load files\n",
        "            imgs = [self.__loadpredict__(filename) for filename in filenames]\n",
        "            # create numpy batch\n",
        "            imgs = np.array(imgs)\n",
        "            return imgs, filenames\n",
        "        # train mode: return images and masks\n",
        "        else:\n",
        "            # load files\n",
        "            items = [self.__load__(filename) for filename in filenames]\n",
        "            # unzip images and masks\n",
        "            imgs, msks = zip(*items)\n",
        "            # create numpy batch\n",
        "            imgs = np.array(imgs,dtype=float)\n",
        "            msks = np.array(msks,dtype=float)\n",
        "            return imgs, msks\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.filenames)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.predict:\n",
        "            # return everything\n",
        "            return int(np.ceil(len(self.filenames) / self.batch_size))\n",
        "        else:\n",
        "            # return full batches only\n",
        "            return int(len(self.filenames) / self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSW6OUooTASM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=32, image_size=256, shuffle=True, augment=True, predict=False)\n",
        "valid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=32, image_size=256, shuffle=False, predict=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0L4DkLYTASQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA2OfLOOU4PA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b5fa1a61-55ca-4d2b-a350-5d6ef5e9486d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JU7a7IfFTASn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate, checkpoint], epochs=5, use_multiprocessing=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXXelvU-J0OH",
        "colab_type": "text"
      },
      "source": [
        "## Model2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2ptNby-Jxap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg_block(layer_in, n_filters, n_conv):\n",
        "    for _ in range(n_conv):\n",
        "        layer_in = keras.layers.Conv2D(n_filters, (3,3), padding='same', activation='relu')(layer_in)\n",
        "    # add max pooling layer\n",
        "    layer_in = keras.layers.MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
        "    return layer_in\n",
        " \n",
        "# define model input\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P9vIGssJ_Pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visible=keras.layers.Input(shape=(224,224,1))\n",
        "layer=vgg_block(visible,8,2)\n",
        "layer=vgg_block(layer,16,2)\n",
        "layer=vgg_block(layer,32,2)\n",
        "layer=vgg_block(layer,64,3)\n",
        "layer=vgg_block(layer,128,3)\n",
        "layer = keras.layers.BatchNormalization(momentum=0.9)(layer)\n",
        "layer = keras.layers.LeakyReLU(0)(layer)\n",
        "layer = keras.layers.Conv2D(1, 1, activation='sigmoid')(layer)\n",
        "outputs = keras.layers.UpSampling2D(2**5)(layer)\n",
        "model1 = Model(inputs=visible, outputs=outputs)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvQ3rK-WLDFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "246c2053-573e-430e-93de-11e3550e9b15"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 224, 224, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 224, 224, 8)       80        \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 224, 224, 8)       584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 112, 112, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 112, 112, 16)      1168      \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 112, 112, 16)      2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 56, 56, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 56, 56, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 56, 56, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 7, 7, 1)           129       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 224, 224, 1)       0         \n",
            "=================================================================\n",
            "Total params: 480,057\n",
            "Trainable params: 479,801\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2hIRYDUUTr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create network and compiler\n",
        "model.compile(optimizer='adam',\n",
        "              loss=iou_bce_loss,\n",
        "              metrics=['accuracy', mean_iou])\n",
        "\n",
        "# cosine learning rate annealing\n",
        "PATIENCE = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyKxnZs9TASj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define iou or jaccard loss function\n",
        "def iou_loss(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    y_pred = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    score = (intersection + 1.) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n",
        "    return 1 - score\n",
        "\n",
        "# combine bce loss and iou loss\n",
        "def iou_bce_loss(y_true, y_pred):\n",
        "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)\n",
        "\n",
        "# mean iou as a metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    y_pred = tf.round(y_pred)\n",
        "    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
        "    smooth = tf.ones(tf.shape(intersect))\n",
        "    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeI1ob62UvyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_annealing(x):\n",
        "    lr = 0.001\n",
        "    epochs = 5\n",
        "    return lr*(np.cos(np.pi*x/epochs)+1.)/2\n",
        "learning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GUQHl6Y-NwPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bacaffaa-b207-4525-b285-f986a02cfa57"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "checkpoint = ModelCheckpoint(\"model-seg-{val_mean_iou:.2f}.h5\", monitor=\"val_mean_iou\", verbose=1, save_best_only=True,\n",
        "                             save_weights_only=True, mode=\"max\") \n",
        "stop = EarlyStopping(monitor=\"val_mean_iou\", patience=PATIENCE, mode=\"max\") # Stop early, if the validation error deteriorates\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_mean_iou\", factor=0.2, patience=10, min_lr=1e-5, verbose=1, mode=\"max\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyM_q1M3Nidq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate, checkpoint,stop,reduce_lr], epochs=5, use_multiprocessing=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tzkcFiLNY2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for imgs, msks in valid_gen:\n",
        "    # predict batch of images\n",
        "    preds = model.predict(imgs)\n",
        "    # create figure\n",
        "    f, axarr = plt.subplots(4, 8, figsize=(20,15))\n",
        "    axarr = axarr.ravel()\n",
        "    axidx = 0\n",
        "    # loop through batch\n",
        "    for img, msk, pred in zip(imgs, msks, preds):\n",
        "        # plot image\n",
        "        axarr[axidx].imshow(img[:, :, 0])\n",
        "        # threshold true mask\n",
        "        comp = msk[:, :, 0] > 0.5\n",
        "        # apply connected components\n",
        "        comp = measure.label(comp)\n",
        "        # apply bounding boxes\n",
        "        predictionString = ''\n",
        "        for region in measure.regionprops(comp):\n",
        "            # retrieve x, y, height and width\n",
        "            y, x, y2, x2 = region.bbox\n",
        "            height = y2 - y\n",
        "            width = x2 - x\n",
        "            axarr[axidx].add_patch(patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='b',facecolor='none'))\n",
        "        # threshold predicted mask\n",
        "        comp = pred[:, :, 0] > 0.5\n",
        "        # apply connected components\n",
        "        comp = measure.label(comp)\n",
        "        # apply bounding boxes\n",
        "        predictionString = ''\n",
        "        for region in measure.regionprops(comp):\n",
        "            # retrieve x, y, height and width\n",
        "            y, x, y2, x2 = region.bbox\n",
        "            height = y2 - y\n",
        "            width = x2 - x\n",
        "            axarr[axidx].add_patch(patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='r',facecolor='none'))\n",
        "        axidx += 1\n",
        "    plt.show()\n",
        "    # only plot one batch\n",
        "    break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}